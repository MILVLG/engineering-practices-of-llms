# 实验一：小型LLM预训练与评估

## 实验目标与项目介绍

本实验旨在帮助学生掌握大语言模型（LLM）预训练的基本技术和流程。通过本实验，学生将学习如何准备预训练数据集、配置预训练环境、执行模型预训练任务，并对预训练后的模型进行评估。实验内容涵盖了数据处理、模型配置、训练优化等关键环节，旨在提升学生对LLM预训练技术的理解和实践能力。

本项目的实验代码在 [MindSpeed-LLM](https://gitee.com/ascend/MindSpeed-LLM) 上改造而成，针对本次实践的需求优化了实验脚本（特别是`MindSpeed-LLM/scripts`中的内容）和部分代码。

## 实验依赖与环境配置

本项目的基本依赖情况如下表所示：

| 加速卡型号 | 驱动和CANN版本 | Python版本 | 主要Python包依赖 |
|------------|----------------|------------|------------------|
| 昇腾910B   | Ascend HDK 23.0.6，CANN 8.0.RC3 | Python 3.10  | torch 2.5.1，torch-npu 2.5.1.post1，transformers 4.43.2 等 |

请参考`docs/environment.md`文件配置本次实验所需的环境。

## 实验设计与指导

### 实验设定与流程

我们对小型LLM的从头预训练任务进行了如下设定：
- 模型设定：采用类似llama2的模型架构，参数量在500M左右（<530M）,具体架构配置见`scripts/pretrain_zen_500m_ptd.sh`，示例脚本将模型均命名为`zen-500m`，你也可以取自己喜欢的名字。
- Tokenizer：使用`assets/zen_tokenizer`，是项目组预先基于`Ultra-FineWeb-ShaoZW_subset`数据集训练得到的SentencePiece tokenizer。
- 预训练数据集：基于`Ultra-FineWeb-ShaoZW_subset`数据集，使用`scripts/sample_data.sh`脚本采样存储规模为50GB的预训练数据集，可自行调整采样策略（详见[数据集准备](#数据集准备)部分）。
- 研究性任务：针对预训练过程中的训练吞吐效率和模型性能两个维度，各选一个（或多个）影响因子，进行消融实验和分析，具体实验设计见[消融实验](#消融实验)部分。

请参考下图工作流合理分配小组工作，安排实验进度：

![实验工作流](./docs/workflow.png)

### 数据集准备

### 模型预训练

### 模型评估

### 消融实验

## 实践作业提交内容

- 项目输出的预训练log文件和评估log文件
- 实验报告，内容包括但不限于实验经过记录、预训练与评估结果分析、消融实验结果与分析等
